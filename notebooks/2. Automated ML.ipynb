{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Machine Learning Model with Automated ML\n",
        "\n",
        "\n",
        "In this notebook we'll be using Azure Automated ML to train a machine learning model capable of determining the best cluster for a COVID-19 scientific article. It builds upon the work done in the *Data Preparation* notebook."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll import Azure ML SDK modules needed, and do a quick sanity-check on the SDK version"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Dataset, Workspace, Experiment\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.automl.core.featurization.featurizationconfig import FeaturizationConfig\n",
        "\n",
        "print(\"AML SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AML SDK version: 1.48.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1676845328922
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll start by retrieving the ML workspace used to manage our work"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve your ML workspace\n",
        "ws = Workspace.from_config()\n",
        "print(ws)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Workspace.create(name='mlw-gai1-f4xzq', subscription_id='23529470-ba17-4d8a-9f0c-064e63a49c33', resource_group='rg-gai1-f4xzq')\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1676845333506
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to be able to launch an Automated ML run we need to provision a compute cluster first. If one already exists then we'll use that one, otherwise we'll create a new one"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# The name of the compute instance\n",
        "compute_name = 'aml-compute-cpu'\n",
        "# The minimum and maximum number of nodes of the compute instance\n",
        "compute_min_nodes = 0\n",
        "# Setting the number of maximum nodes to a higher value will allow Automated ML to run more experiments in parallel, but will also inccrease your costs\n",
        "compute_max_nodes = 4\n",
        "\n",
        "vm_size = 'STANDARD_DS3_V2'\n",
        "\n",
        "# Check existing compute targets in the workspace for a compute with this name\n",
        "if compute_name in ws.compute_targets:\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    if compute_target and type(compute_target) is AmlCompute:\n",
        "        print(f'Found existing compute target: {compute_name}')    \n",
        "else:\n",
        "    print(f'A new compute target is needed: {compute_name}')\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
        "                                                                min_nodes = compute_min_nodes, \n",
        "                                                                max_nodes = compute_max_nodes)\n",
        "\n",
        "    # Create the cluster\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
        "    \n",
        "    # Wait for provisioning to complete\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing compute target: aml-compute-cpu\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1676845336503
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring the Automated ML experiment\n",
        "\n",
        "We'll use the `COVID19Articles_Train` dataset that we registered in the previous notebook for training the model. In order to speed up training we'll ignore all columns except the word vectors calculated using Doc2Vec."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the COVID19Articles_Train dataset from the workspace\n",
        "train_data = Dataset.get_by_name(ws, 'COVID19Articles_Train')\n",
        "\n",
        "# Ignore all columns except the word vectors\n",
        "columns_to_ignore = ['sha', 'source_x', 'title', 'doi', 'pmcid', 'pubmed_id', 'license', 'abstract', 'publish_time', 'authors', 'journal', 'mag_id',\n",
        "                     'who_covidence_id', 'arxiv_id', 'pdf_json_files', 'pmc_json_files', 'url', 's2_id' ]\n",
        "train_data = train_data.drop_columns(columns_to_ignore) \n",
        "\n",
        "\n",
        "# Configura Automated ML\n",
        "automl_config = AutoMLConfig(task = \"classification\",\n",
        "                             # Use weighted area under curve metric to evaluate the models\n",
        "                             primary_metric='AUC_weighted',\n",
        "                             \n",
        "                             # Use all columns except the ones we decided to ignore\n",
        "                             training_data = train_data,\n",
        "                             \n",
        "                             # The values we're trying to predict are in the `cluster` column\n",
        "                             label_column_name = 'cluster',\n",
        "                             \n",
        "                             # Evaluate the model with 5-fold cross validation\n",
        "                             n_cross_validations=5,\n",
        "                             \n",
        "                             # The experiment should be stopped after 15 minutes, to minimize cost\n",
        "                             experiment_timeout_hours=.25,\n",
        "                             \n",
        "                             # Automated ML can try at most 4 models at the same time, this is also limited by the compute instance's maximum number of nodes\n",
        "                             max_concurrent_iterations=4,\n",
        "                             \n",
        "                             # An iteration should be stopped if it takes more than 5 minutes\n",
        "                             iteration_timeout_minutes=5,\n",
        "                             \n",
        "                             compute_target=compute_target\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1676845340571
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have configured the Automated ML run, we can submit it in one of the workspace's experiments. Note that this step should take around 15 minutes, according to the `experiment_timeout_minutes` setting.\n",
        "\n",
        "**NOTE**:\n",
        "\n",
        "If this is the first time you are launching an experiment run in the Azure Machine Learning workspace, additional time will be needed to start the Compute Cluster and deploy the container images required to execute."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the `COVID19_Classification` dataset\n",
        "exp = Experiment(ws, 'COVID19_Classification')\n",
        "run = exp.submit(automl_config, show_output=True)\n",
        "\n",
        "# Retrieve the best performing run and its corresponding model from the aggregated Automated ML run\n",
        "best_run, best_model = run.get_output()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting remote run.\nNo run_configuration provided, running on aml-compute-cpu with default configuration\nRunning on remote compute: aml-compute-cpu\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>COVID19_Classification</td><td>AutoML_6562f9c9-6719-467b-9eaf-28445c88169e</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_6562f9c9-6719-467b-9eaf-28445c88169e?wsid=/subscriptions/23529470-ba17-4d8a-9f0c-064e63a49c33/resourcegroups/rg-gai1-f4xzq/workspaces/mlw-gai1-f4xzq&amp;tid=178121b9-4c42-4e6f-8611-0350f0190053\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nCurrent status: FeaturesGeneration. Generating features for the dataset.\nCurrent status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\nCurrent status: ModelSelection. Beginning model selection.\n\n********************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Class balancing detection\nSTATUS:       ALERTED\nDESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\nDETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n+------------------------------+--------------------------------+--------------------------------------+\n|Size of the smallest class    |Name/Label of the smallest class|Number of samples in the training data|\n+==============================+================================+======================================+\n|1                             |6, 8, 9                         |400                                   |\n+------------------------------+--------------------------------+--------------------------------------+\n\n********************************************************************************************\n\nTYPE:         Missing feature values imputation\nSTATUS:       PASSED\nDESCRIPTION:  No feature missing values were detected in the training data.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\nTYPE:         High cardinality feature detection\nSTATUS:       PASSED\nDESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n\n********************************************************************************************\n\n********************************************************************************************\nITER: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************\n\n ITER   PIPELINE                                       DURATION            METRIC      BEST\n    0   MaxAbsScaler LightGBM                          0:00:31             0.9582    0.9582\n    1   MaxAbsScaler XGBoostClassifier                 0:00:26             0.9524    0.9582\n    2   MaxAbsScaler ExtremeRandomTrees                0:00:18             0.9137    0.9582\n    3   MaxAbsScaler RandomForest                      0:00:18             0.8772    0.9582\n    4   StandardScalerWrapper LightGBM                 0:00:19             0.9520    0.9582\n    5   StandardScalerWrapper KNN                      0:00:19             0.9103    0.9582\n    6   SparseNormalizer XGBoostClassifier             0:00:21             0.9280    0.9582\n    7   SparseNormalizer RandomForest                  0:00:21             0.9529    0.9582\n    8   RobustScaler KNN                               0:00:20             0.9059    0.9582\n    9   MinMaxScaler RandomForest                      0:00:21             0.9061    0.9582\n   10   StandardScalerWrapper LogisticRegression       0:00:19             0.9757    0.9757\n   11   StandardScalerWrapper SVM                      0:00:20             0.9754    0.9757\n   12   StandardScalerWrapper XGBoostClassifier        0:00:20             0.9178    0.9757\n   13   SparseNormalizer KNN                           0:00:18             0.8995    0.9757\n   14   RobustScaler ExtremeRandomTrees                0:00:19             0.8848    0.9757\n   15   SparseNormalizer XGBoostClassifier             0:00:21             0.9174    0.9757\n   16   MinMaxScaler ExtremeRandomTrees                0:00:19             0.9502    0.9757\n   17   MinMaxScaler ExtremeRandomTrees                0:00:19             0.9341    0.9757\n   18   SparseNormalizer LightGBM                      0:00:19             0.9483    0.9757\n   19   MaxAbsScaler ExtremeRandomTrees                0:00:24             0.9509    0.9757\n   21   StandardScalerWrapper RandomForest             0:00:34             0.9571    0.9757\n"
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the Automated ML run has finished, we can visualize its models and see how they measure up according to several metrics. Remember, the higher the *AUC_weighter*, the better."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}